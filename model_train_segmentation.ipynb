{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o86gn1nG6DQ3"
      },
      "source": [
        "\n",
        "\n",
        "### Image segementaion model train 2022 Nov\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import packages"
      ],
      "metadata": {
        "id": "8Yj608dbS6E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WblwuyYcJzm"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision --upgrade\n",
        "!pip install grad-cam\n",
        "!pip install timm\n",
        "!pip install imagecodecs\n",
        "!pip install git+https://github.com/qubvel/segmentation_models.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lME-yOdUPlEO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "import os \n",
        "from os import path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# read tiff\n",
        "import zipfile\n",
        "from tifffile import imread\n",
        "from torchvision.transforms import ToTensor\n",
        "import random\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unet import UNet\n",
        "from keyholeDataset import Keyhole\n",
        "from augmentation import get_training_augmentation\n",
        "from loss import DiceBCELoss\n",
        "from utils import plot_2_sidebyside, plot_3_sidebyside, save_model\n",
        "from train import train\n",
        "from validation import validation\n",
        "# import segmentation_models_pytorch as smp\n"
      ],
      "metadata": {
        "id": "cV2IGWBqOtsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmLun9tNDQuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Initiate a model"
      ],
      "metadata": {
        "id": "DyJE_hxsDUg2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU6DxoE9wfCp"
      },
      "outputs": [],
      "source": [
        "#model = torch.hub.load('milesial/Pytorch-UNet', 'unet_carvana', pretrained=True, scale=0.5)\n",
        "\n",
        "model = UNet(n_channels=3, n_classes=1, bilinear=1)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efmaWFtZG3oU"
      },
      "outputs": [],
      "source": [
        "# # load model\n",
        "# checkpoint = torch.load(\"unet_test_epoch_51\")\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SgcmudGvDX5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. load data + specify batch_size and epochs"
      ],
      "metadata": {
        "id": "XZupFMnMDY3g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RTL_ifQPfi4"
      },
      "outputs": [],
      "source": [
        "!mkdir Keyhole\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/DL_segmentation_data/keyhole_segmentation_data.zip', 'r') as zip:\n",
        "  zip.extractall(path='/content/Keyhole')\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \" + str(cuda)+\" with num_workers = \"+str(num_workers))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyMdtFLAUNx1"
      },
      "outputs": [],
      "source": [
        "# need to write config file to make this part elegent\n",
        "batch_size = 1\n",
        "epochs = 300\n",
        "\n",
        "train_dataset = Keyhole('/content/Keyhole/keyhole_segmentation_data', transform=get_training_augmentation(), mode=\"train\", csv_name=\"/image_and_split_1.csv\")\n",
        "val_dataset = Keyhole('/content/Keyhole/keyhole_segmentation_data', transform=None , mode=\"val\", csv_name=\"/image_and_split_1.csv\")\n",
        "test_dataset = Keyhole('/content/Keyhole/keyhole_segmentation_data', transform=None, mode=\"test\", csv_name=\"/image_and_split_1.csv\")\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Valid size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQA5wFlLf0nG"
      },
      "outputs": [],
      "source": [
        "pred_masks = []\n",
        "for i, batch in enumerate(train_loader):\n",
        "      print(\"i = \", i)\n",
        "      x = batch['image'].float().to(device) \n",
        "      y = batch['mask'].float().to(device) \n",
        "      assert(len(x) == len(y))\n",
        "      #print(\"x shape\", x.shape) #torch.Size([1, 3, 572, 572])\n",
        "      #print(\"y shape\", y.shape) #torch.Size([1, 1, 572, 572])\n",
        "      # yp = model(x)\n",
        "      # print(\"yp shape\", yp.shape)#torch.Size([1, 1, 572, 572])\n",
        "      plot_2_sidebyside(x.detach().cpu().numpy()[0][0], \n",
        "                      y.detach().cpu().numpy()[0][0])\n",
        "                      \n",
        "      \n",
        "      # plot_3_sidebyside(x.detach().cpu().numpy()[0][0], \n",
        "      #                 y.detach().cpu().numpy()[0][0], \n",
        "      #                 yp.detach().cpu().numpy()[0][0]), (yp.detach().cpu().numpy()[0][0]>0.5).astype(int))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-YnS4xUz8Uv"
      },
      "source": [
        "## 4. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm9TIn-TzqWg"
      },
      "outputs": [],
      "source": [
        "# #del model\n",
        "# torch.cuda.empty_cache()\n",
        "# model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkEnXPr6xB8Y"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 572, 572))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3N213DI-B0xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXz1ANLOMIhs"
      },
      "outputs": [],
      "source": [
        " # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
        " # https://github.com/milesial/Pytorch-UNet/blob/master/train.py\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=1e-8, momentum=0.99)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2)  # goal: maximize Dice score\n",
        "grad_scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DizdnLL_RMv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "amp = True\n",
        "train_losses= []\n",
        "val_losses= []\n",
        "for epoch in range(1, epochs+1):\n",
        "  train_loss = train(model, device, train_loader, optimizer, criterion, scheduler, grad_scaler, epoch, epochs=300, amp=True)\n",
        "  train_losses.append(train_loss)\n",
        "  val_loss = validation(model, device, val_loader, optimizer, criterion, scheduler, epoch, epochs=300, amp=True)\n",
        "  val_losses.append(val_loss)\n",
        "  if epoch in {50, 100, 150, 200, 250, 300}:\n",
        "    save_model(model, epoch, \"unet\", optimizer, scheduler, grad_scaler, batch_size)"
      ],
      "metadata": {
        "id": "LevPEXB4zqNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Save model and plot loss"
      ],
      "metadata": {
        "id": "tJs1KSeSDs2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjnZnxe5Bqq5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(loss_rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQMKze3EH6zI"
      },
      "outputs": [],
      "source": [
        "save_model(model, 50, \"unet_test\", optimizer, scheduler, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pow5X7o2HkYO"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"unet_test_epoch_51\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6Udh7QxmlVM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "o86gn1nG6DQ3"
      ]
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}